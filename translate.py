import pandas as pd
from google.cloud import translate_v2 as translate
import html
import os
import csv
import re

# --- é…ç½®åŒºåŸŸ ---
GLOSSARY_FILE = "glossary.csv"  # ä½ çš„æ— å¤´æœ¯è¯­è¡¨æ–‡ä»¶

# åŠ è½½ç¯å¢ƒå˜é‡ä»¥ä½¿ç”¨ Google å‡­æ®
os.environ["GOOGLE_APPLICATION_CREDENTIALS"] = (
    "C:\\Code\\tswloc\\lithe-hallway-473510-s6-cd50ed72e0d4.json"
)


def load_glossary(file_path):
    """åŠ è½½æ— è¡¨å¤´CSVæœ¯è¯­è¡¨ï¼šç¬¬ä¸€åˆ—åŸæ–‡ï¼Œç¬¬äºŒåˆ—è¯‘æ–‡"""
    glossary = {}
    if not os.path.exists(file_path):
        print(f"âš ï¸ æœªæ‰¾åˆ°æœ¯è¯­è¡¨æ–‡ä»¶: {file_path}ï¼Œå°†è·³è¿‡æš´åŠ›æ›¿æ¢ã€‚")
        return glossary

    with open(file_path, mode="r", encoding="utf-8") as f:
        reader = csv.reader(f)
        for row in reader:
            if len(row) >= 2:
                # å­˜å…¥å­—å…¸ï¼š{ "Power Handle": "åŠŸç‡æ‰‹æŸ„" }
                glossary[row[0].strip()] = row[1].strip()

    # æŒ‰é•¿åº¦å€’åºæ’åºï¼Œé˜²æ­¢çŸ­è¯ç ´åé•¿è¯ï¼ˆå¦‚é˜²æ­¢ 'Train' ç ´å 'Train Brake'ï¼‰
    return dict(sorted(glossary.items(), key=lambda x: len(x[0]), reverse=True))

def apply_glossary(original_text, translated_text, glossary):
    """
    æ ¹æ®åŸæ–‡åˆ¤å®šæ˜¯å¦åŒ…å«æœ¯è¯­ï¼Œè‹¥åŒ…å«ï¼Œåˆ™åœ¨è¯‘æ–‡ä¸­å¼ºåˆ¶ä¿®æ­£ã€‚
    """
    if not isinstance(translated_text, str) or not glossary:
        return translated_text

    for en_term, zh_term in glossary.items():
        # 1. æ£€æŸ¥ã€åŸæ–‡ã€‘ä¸­æ˜¯å¦åŒ…å«è¯¥æœ¯è¯­ (å¿½ç•¥å¤§å°å†™)
        if en_term.lower() in original_text.lower():
            # 2. å¦‚æœåŸæ–‡æœ‰è¿™ä¸ªè¯ï¼Œæˆ‘ä»¬éœ€è¦åœ¨ã€è¯‘æ–‡ã€‘ä¸­æ‰¾åˆ° Google å¯èƒ½ç¿»é”™çš„ç»“æœå¹¶æ›¿æ¢
            # è¿™é‡Œæœ‰ä¸ªéš¾ç‚¹ï¼šæˆ‘ä»¬ä¸çŸ¥é“ Google æŠŠè¿™ä¸ªè¯ç¿»æˆäº†ä»€ä¹ˆï¼ˆå¯èƒ½ç¿»æˆ Aï¼Œä¹Ÿå¯èƒ½ç¿»æˆ Bï¼‰
            # æš´åŠ›ç­–ç•¥ï¼šå¦‚æœè¯‘æ–‡é‡Œå·²ç»æ²¡æœ‰è‹±æ–‡åŸæ–‡äº†ï¼Œæˆ‘ä»¬å¯èƒ½éœ€è¦æ›´å¤æ‚çš„æ˜ å°„ã€‚

            # ç­–ç•¥ Aï¼šç›´æ¥æŠŠè¯‘æ–‡ä¸­å¯¹åº”çš„éƒ¨åˆ†æ¢æ‰ï¼ˆå¦‚æœè¯‘æ–‡ä¿ç•™äº†éƒ¨åˆ†è‹±æ–‡ï¼‰
            pattern = re.compile(re.escape(en_term), re.IGNORECASE)
            if pattern.search(translated_text):
                translated_text = pattern.sub(zh_term, translated_text)
            else:
                # å¦‚æœä½ å¸Œæœ›æœ€æš´åŠ›ï¼šå¦‚æœåŸæ–‡åªæœ‰è¿™ä¸ªè¯ï¼Œç›´æ¥è¿”å›æœ¯è¯­è¡¨è¯‘æ–‡
                if original_text.strip().lower() == en_term.lower():
                    return zh_term

    # é¢å¤–ä¿®å¤å ä½ç¬¦
    translated_text = translated_text.replace("{ ", "{").replace(" }", "}")
    return translated_text


def translate_tsw_csv(input_file, output_file, target_lang="zh-CN"):
    # 0. åŠ è½½æœ¬åœ°æœ¯è¯­è¡¨
    glossary = load_glossary(GLOSSARY_FILE)
    print(f"âœ… å·²åŠ è½½æœ¯è¯­è¯æ¡: {len(glossary)} æ¡")

    # 1. åˆå§‹åŒ–å®¢æˆ·ç«¯
    client = translate.Client()

    # 2. è¯»å– CSV
    print(f"æ­£åœ¨åŠ è½½: {input_file}")
    df = pd.read_csv(input_file)

    # 3. æå–å”¯ä¸€åŸæ–‡è¿›è¡Œç¿»è¯‘
    # fix å¯èƒ½å­˜åœ¨çš„ NaN é—®é¢˜
    df["source"] = df["source"].fillna("")
    unique_sources = df["source"].unique().tolist()
    print(f"æ£€æµ‹åˆ°æ€»è¡Œæ•°: {len(df)}, å”¯ä¸€å¾…ç¿»è¯‘è¯æ¡æ•°: {len(unique_sources)}")

    translated_map = {}
    batch_size = 50

    print(f"å¼€å§‹è°ƒç”¨ Google API ç¿»è¯‘...")
    for i in range(0, len(unique_sources), batch_size):
        batch = unique_sources[i : i + batch_size]
        try:
            results = client.translate(batch, target_language=target_lang)

            for original, res in zip(batch, results):
                # è§£ç  HTML å®ä½“
                translated_text = html.unescape(res["translatedText"])

                translated_text = apply_glossary(original, translated_text, glossary)

                translated_map[original] = translated_text

            print(
                f"è¿›åº¦: {min(i + batch_size, len(unique_sources))}/{len(unique_sources)}"
            )
        except Exception as e:
            print(f"ç¿»è¯‘æ‰¹æ¬¡ {i} å¤±è´¥: {e}")
            for text in batch:
                translated_map[text] = text

    # 4. æ˜ å°„å› Translation åˆ—
    print("æ­£åœ¨åŒ¹é…ç¿»è¯‘ç»“æœ...")
    df["Translation"] = df["source"].map(translated_map)

    # 5. ä¿å­˜ç»“æœ
    df.to_csv(output_file, index=False, encoding="utf-8-sig")
    print(f"ğŸ‰ ç¿»è¯‘å¹¶ä¿®æ­£å®Œæˆï¼å·²ä¿å­˜è‡³: {output_file}")


if __name__ == "__main__":
    # é…ç½®
    file = "AABS_Class350_BTP.locres.csv"
    out_file = file.replace(".locres.csv", "_translated.csv")
    config = {
        "input_file": file,
        "output_file": out_file,
        "target_lang": "zh-CN",
    }

    translate_tsw_csv(**config)
